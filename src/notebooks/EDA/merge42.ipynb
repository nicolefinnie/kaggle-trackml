{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import collections as coll\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import merge as merge\n",
    "import extension as ext\n",
    "import zroutlier as zro\n",
    "import free_hits as free\n",
    "import track_score as score2\n",
    "import straight_tracks as strt\n",
    "import eda_utils as eda\n",
    "import r0outlier as r0o\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../../../input/train_1'\n",
    "event_id = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event000001000 memory usage 18.46 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "event_prefix = 'event00000' + str(event_id)\n",
    "hits, cells, particles, truth = load_event(os.path.join(TRAIN_PATH, event_prefix))\n",
    "\n",
    "mem_bytes = (hits.memory_usage(index=True).sum() \n",
    "             + cells.memory_usage(index=True).sum() \n",
    "             + particles.memory_usage(index=True).sum() \n",
    "             + truth.memory_usage(index=True).sum())\n",
    "print('{} memory usage {:.2f} MB'.format(event_prefix, mem_bytes / 2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "helix_root_path = '../../1000_r0_exp3/event_' + str(event_id) + '_labels_train_helix'\n",
    "labels_helix1 = pd.read_csv(helix_root_path + '1.csv').label.values\n",
    "labels_helix2 = pd.read_csv(helix_root_path + '2.csv').label.values\n",
    "labels_helix3 = pd.read_csv(helix_root_path + '3.csv').label.values\n",
    "labels_helix4 = pd.read_csv(helix_root_path + '4.csv').label.values\n",
    "labels_helix5 = pd.read_csv(helix_root_path + '5.csv').label.values\n",
    "labels_helix6 = pd.read_csv(helix_root_path + '6.csv').label.values\n",
    "labels_helix7 = pd.read_csv(helix_root_path + '7.csv').label.values\n",
    "labels_helix8 = pd.read_csv(helix_root_path + '8.csv').label.values\n",
    "labels_helix9 = pd.read_csv(helix_root_path + '9.csv').label.values\n",
    "labels_helix10 = pd.read_csv(helix_root_path + '10.csv').label.values\n",
    "labels_helix11 = pd.read_csv(helix_root_path + '11.csv').label.values\n",
    "labels_helix12 = pd.read_csv(helix_root_path + '12.csv').label.values\n",
    "labels_helix13 = pd.read_csv(helix_root_path + '13.csv').label.values\n",
    "labels_helix14 = pd.read_csv(helix_root_path + '14.csv').label.values\n",
    "labels_helix15 = pd.read_csv(helix_root_path + '15.csv').label.values\n",
    "labels_helix16 = pd.read_csv(helix_root_path + '16.csv').label.values\n",
    "labels_helix17 = pd.read_csv(helix_root_path + '17.csv').label.values\n",
    "labels_helix18 = pd.read_csv(helix_root_path + '18.csv').label.values\n",
    "labels_helix19 = pd.read_csv(helix_root_path + '19.csv').label.values\n",
    "labels_helix20 = pd.read_csv(helix_root_path + '20.csv').label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission\n",
    "\n",
    "def score_one_submission(event_id, hits, labels, truth):\n",
    "    submission = create_one_event_submission(event_id, hits, labels)\n",
    "    score = score_event(truth, submission)\n",
    "    print(\"Score for event %d: %.8f\" % (event_id, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hits['z_abs'] = hits.z.abs()\n",
    "#hits['r'] = np.sqrt(hits.x**2+hits.y**2)\n",
    "#hits['zr'] = hits['z'] / hits['r']\n",
    "#hits['azr'] = np.arctan2(hits['z'], hits['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block if you want to see the distribution of perfect vs short vs imperfect vs horrible\n",
    "# tracks, by comparing to ground truth\n",
    "helix6 = np.copy(labels_helix9)\n",
    "#helix6 = merge.remove_outliers(helix6, hits, smallest_track_size=6, aggressive=False, print_counts=False)\n",
    "(helix6, small_count) = merge.remove_small_tracks(helix6, smallest_track_size=6)\n",
    "#helix6 = r0o.remove_badr0_tracks(helix6, hits)\n",
    "helix6 = merge.renumber_labels(helix6)\n",
    "tracks = np.unique(helix6)\n",
    "short_tracks = []\n",
    "perfect_tracks = []\n",
    "imperfect_tracks = []\n",
    "horrible_tracks = []\n",
    "for track in tracks:\n",
    "    if track == 0: continue\n",
    "    tix = np.where(helix6 == track)[0]\n",
    "    if len(tix) < 6: continue\n",
    "    else:\n",
    "        (is_match, correct,incorrect) = eda.track_distance_from_truth(track, helix6, hits, truth)\n",
    "        if is_match:\n",
    "            perfect_tracks.append(track)\n",
    "        elif incorrect == 0:\n",
    "            short_tracks.append(track)\n",
    "        elif incorrect <= 4 and correct >= incorrect:\n",
    "            imperfect_tracks.append(track)\n",
    "        else:\n",
    "            horrible_tracks.append(track)\n",
    "\n",
    "print('Total tracks:     ' + str(len(tracks)))\n",
    "print('Perfect tracks:   ' + str(len(perfect_tracks)))\n",
    "print('Short tracks:     ' + str(len(short_tracks)))\n",
    "print('Imperfect tracks: ' + str(len(imperfect_tracks)))\n",
    "print('Horrible tracks:  ' + str(len(horrible_tracks)))\n",
    "# Helix1: 8143, perfect 1972, short 1364, imperfect 3547, horrible 1259\n",
    "# Helix2: 7666, perfect 2020, short 1170, imperfect 3522, horrible 953\n",
    "# Helix3: 6717, perfect 1783, short 1589, imperfect 2696, horrible 648\n",
    "# Helix4: 6688, perfect 1547, short 1649, imperfect 2780, horrible 711\n",
    "# Helix5: 6645, perfect 1600, short 1763, imperfect 2781, horrible 500\n",
    "# Helix6: 7436, perfect 1755, short 1716, imperfect 3361, horrible 603\n",
    "# Helix7: 7451, perfect 1795, short 1795, imperfect 3299, horrible 589\n",
    "# Helix8: 7421, perfect 1734, short 1638, imperfect 3302, horrible 746\n",
    "# Helix9: 7414, perfect 1807, short 1699, imperfect 3276, horrible 631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tracks_based_on_quality(labels, hits):\n",
    "    \"\"\"Split input tracks into 3 categories - strong, medium, weak.\n",
    "    Splitting is determined mainly by how consistent the track helix curvature is.\"\"\"\n",
    "    strong_tracks = []\n",
    "    medium_tracks = []\n",
    "    weak_tracks = []\n",
    "    hits['z_abs'] = hits.z.abs()\n",
    "    tracks, counts = np.unique(labels, return_counts=True)\n",
    "    strong_labels = np.zeros_like(labels)\n",
    "    medium_labels = np.zeros_like(labels)\n",
    "    weak_labels = np.zeros_like(labels)\n",
    "    for ix, track in enumerate(tracks):\n",
    "        if track == 0: continue\n",
    "        if counts[ix] < 5:\n",
    "            if counts[ix] > 3:\n",
    "                medium_tracks.append(track)\n",
    "            # else, discard, too short.\n",
    "            continue\n",
    "        (curv1, curv2, curv3) = r0o.find_track_curvature(track, labels, hits)\n",
    "        if np.sign(curv1) != np.sign(curv2) or np.sign(curv1) != np.sign(curv3):\n",
    "            weak_tracks.append(track)\n",
    "            continue\n",
    "\n",
    "        c1 = min(abs(curv1), abs(curv2))\n",
    "        c2 = max(abs(curv1), abs(curv2))\n",
    "        c3 = abs(curv3)\n",
    "        ratio = 1.0 - c1/c2\n",
    "        if ratio > 0.50:\n",
    "            weak_tracks.append(track)\n",
    "        elif ratio < 0.2:\n",
    "            if counts[ix] > 20 or r0o.is_horrible_track2(track, labels, hits):\n",
    "                medium_tracks.append(track)\n",
    "            else:\n",
    "                strong_tracks.append(track)\n",
    "        else:\n",
    "            medium_tracks.append(track)\n",
    "\n",
    "    for track in strong_tracks:\n",
    "        strong_labels[labels==track] = track\n",
    "    for track in medium_tracks:\n",
    "        medium_labels[labels==track] = track\n",
    "    for track in weak_tracks:\n",
    "        weak_labels[labels==track] = track\n",
    "\n",
    "    return (strong_labels, medium_labels, weak_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_track_quality(labels, hits, truth):\n",
    "    tracks, counts = np.unique(labels, return_counts=True)\n",
    "    short_tracks = 0\n",
    "    perfect_tracks = 0\n",
    "    imperfect_tracks = 0\n",
    "    horrible_tracks = 0\n",
    "    for ix, track in enumerate(tracks):\n",
    "        if track == 0: continue\n",
    "        if counts[ix] < 6: continue\n",
    "\n",
    "        (is_match, correct,incorrect) = eda.track_distance_from_truth(track, labels, hits, truth)\n",
    "        if is_match:\n",
    "            perfect_tracks = perfect_tracks + 1\n",
    "        elif incorrect == 0:\n",
    "            short_tracks = short_tracks + 1\n",
    "        elif incorrect <= 4 and correct >= incorrect:\n",
    "            imperfect_tracks = imperfect_tracks + 1\n",
    "        else:\n",
    "            horrible_tracks = horrible_tracks + 1\n",
    "\n",
    "    print('Total tracks:     ' + str(len(tracks)))\n",
    "    print('Perfect tracks:   ' + str(perfect_tracks))\n",
    "    print('Short tracks:     ' + str(short_tracks))\n",
    "    print('Imperfect tracks: ' + str(imperfect_tracks))\n",
    "    print('Horrible tracks:  ' + str(horrible_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.copy(labels_helix6)\n",
    "score_one_submission(event_id, hits, labels, truth) # 0.63580502\n",
    "(strong, medium, weak) = split_tracks_based_on_quality(labels, hits)\n",
    "score_one_submission(event_id, hits, strong, truth)\n",
    "score_one_submission(event_id, hits, medium, truth)\n",
    "score_one_submission(event_id, hits, weak, truth)\n",
    "# (0.5 weak, 0.1 strong): 0.28793004 (1776/3737), 0.31400817 (1582/5075), 0.03201160 (28/646)\n",
    "# (0.5 weak, 0.15 strong): 0.35599925 (2247/4484), 0.24593896 (1111/4328), 0.03201160 (28/646)\n",
    "# (0.5 weak, 0.2 strong): 0.40582813 (2604/5035), 0.19611008 (754/3777), 0.03201160 (28/646)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_track_quality(strong, hits, truth)\n",
    "display_track_quality(medium, hits, truth)\n",
    "display_track_quality(weak, hits, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_helix1f = merge.remove_outliers(labels_helix1, hits, cells, print_counts=False)\n",
    "labels_helix2f = merge.remove_outliers(labels_helix2, hits, cells, print_counts=False)\n",
    "labels_helix3f = merge.remove_outliers(labels_helix3, hits, cells, print_counts=False)\n",
    "labels_helix4f = merge.remove_outliers(labels_helix4, hits, cells, print_counts=False)\n",
    "labels_helix5f = merge.remove_outliers(labels_helix5, hits, cells, print_counts=False)\n",
    "# LIAM: Add more outlier removal here. Explore different cutoffs (> 0.2?)\n",
    "labels_helix1f = r0o.remove_badr0_tracks(labels_helix1f, hits)\n",
    "labels_helix2f = r0o.remove_badr0_tracks(labels_helix2f, hits)\n",
    "labels_helix3f = r0o.remove_badr0_tracks(labels_helix3f, hits)\n",
    "labels_helix4f = r0o.remove_badr0_tracks(labels_helix4f, hits)\n",
    "labels_helix5f = r0o.remove_badr0_tracks(labels_helix5f, hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_labels.append(labels_helix1f)\n",
    "all_labels.append(labels_helix2f)\n",
    "all_labels.append(labels_helix6)\n",
    "all_labels.append(labels_helix7)\n",
    "all_labels.append(labels_helix8)\n",
    "all_labels.append(labels_helix9)\n",
    "all_labels.append(labels_helix10)\n",
    "all_labels.append(labels_helix11)\n",
    "all_labels.append(labels_helix12)\n",
    "all_labels.append(labels_helix13)\n",
    "all_labels.append(labels_helix14)\n",
    "all_labels.append(labels_helix15)\n",
    "all_labels.append(labels_helix16)\n",
    "all_labels.append(labels_helix17)\n",
    "all_labels.append(labels_helix18)\n",
    "all_labels.append(labels_helix19)\n",
    "all_labels.append(labels_helix20)\n",
    "all_labels.append(labels_helix5f)\n",
    "all_labels.append(labels_helix3f)\n",
    "all_labels.append(labels_helix4f)\n",
    "strong_labels = []\n",
    "medium_labels = []\n",
    "weak_labels = []\n",
    "for label in all_labels:\n",
    "    (strong, medium, weak) = split_tracks_based_on_quality(label, hits)\n",
    "    strong_labels.append(strong)\n",
    "    medium_labels.append(medium)\n",
    "    weak_labels.append(weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_labels(all_labels, hits, truth):\n",
    "    merge_count = 0\n",
    "    labels_merged = np.copy(all_labels[0])\n",
    "    for i in range(len(all_labels)):\n",
    "        if i == 0: continue\n",
    "        labels_merged = merge.heuristic_merge_tracks(labels_merged, all_labels[i], hits, overwrite_limit=6, print_summary=False)\n",
    "        merge_count = merge_count + 1\n",
    "        #message = 'Merged loop 1-' + str(i+1) + ' score for event '\n",
    "        #display_score(event_id, hits, labels_merged, truth, message)\n",
    "        score_one_submission(event_id, hits, labels_merged, truth)\n",
    "    return labels_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.69349524\n",
      "Score for event 1000: 0.71305367\n",
      "Score for event 1000: 0.71612071\n",
      "Score for event 1000: 0.71541384\n",
      "Score for event 1000: 0.71610327\n",
      "Score for event 1000: 0.71606276\n",
      "Score for event 1000: 0.71678072\n",
      "Score for event 1000: 0.71758944\n",
      "Score for event 1000: 0.71822985\n",
      "Score for event 1000: 0.71836265\n",
      "Score for event 1000: 0.71783664\n",
      "Score for event 1000: 0.71893532\n",
      "Score for event 1000: 0.71786945\n",
      "Score for event 1000: 0.71926097\n",
      "Score for event 1000: 0.71846895\n",
      "Score for event 1000: 0.71824668\n",
      "Score for event 1000: 0.71838602\n",
      "Score for event 1000: 0.71876750\n",
      "Score for event 1000: 0.71835409\n"
     ]
    }
   ],
   "source": [
    "all_merged = merge_all_labels(all_labels, hits, truth)\n",
    "# No outlier removal, order 1-9: 0.70948133\n",
    "# outlier removal, 1-2,6-9,5,3,4: 0.71563907\n",
    "# + r0 outlier rem: 0.71652579\n",
    "# + more models(10-20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.51293564\n",
      "Score for event 1000: 0.55977605\n",
      "Score for event 1000: 0.57273489\n",
      "Score for event 1000: 0.58420738\n",
      "Score for event 1000: 0.58764724\n",
      "Score for event 1000: 0.59721682\n",
      "Score for event 1000: 0.60144344\n",
      "Score for event 1000: 0.60531215\n",
      "Score for event 1000: 0.60768387\n",
      "Score for event 1000: 0.61053109\n",
      "Score for event 1000: 0.61255038\n",
      "Score for event 1000: 0.61346986\n",
      "Score for event 1000: 0.61420426\n",
      "Score for event 1000: 0.61569522\n",
      "Score for event 1000: 0.61588087\n",
      "Score for event 1000: 0.61652494\n",
      "Score for event 1000: 0.62397586\n",
      "Score for event 1000: 0.62753788\n",
      "Score for event 1000: 0.62883099\n"
     ]
    }
   ],
   "source": [
    "strong_merged = merge_all_labels(strong_labels, hits, truth)\n",
    "# 0.1 cutoff: 0.47028638\n",
    "# 0.15 cutoff: 0.54866460\n",
    "# 0.2 cutoff: 0.59883933\n",
    "# outlier rem, 0.2 cutoff: 0.60684391\n",
    "# +r0 out. rem: 0.60669428\n",
    "# + models 10-20: 0.62883099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.22760629\n",
      "Score for event 1000: 0.28729900\n",
      "Score for event 1000: 0.31137640\n",
      "Score for event 1000: 0.33276157\n",
      "Score for event 1000: 0.34104471\n",
      "Score for event 1000: 0.38566285\n",
      "Score for event 1000: 0.40904801\n",
      "Score for event 1000: 0.41738492\n",
      "Score for event 1000: 0.42570800\n",
      "Score for event 1000: 0.43047799\n",
      "Score for event 1000: 0.43516841\n",
      "Score for event 1000: 0.43874598\n",
      "Score for event 1000: 0.44446221\n",
      "Score for event 1000: 0.44761954\n",
      "Score for event 1000: 0.44986680\n"
     ]
    }
   ],
   "source": [
    "m2_lbl = medium_labels[0:13]\n",
    "m2_lbl.append(medium_labels[-3])\n",
    "m2_lbl.append(medium_labels[-2])\n",
    "m2_lbl.append(medium_labels[-1])\n",
    "medium_merged = merge_all_labels(m2_lbl, hits, truth)\n",
    "#medium_merged = merge_all_labels(medium_labels, hits, truth)\n",
    "# 0.1 cutoff: 0.50709876\n",
    "# 0.15 cutoff: 0.43838218\n",
    "# 0.2 cutoff: 0.38796599\n",
    "# outlier rem, 0.2 cutoff: 0.36414178\n",
    "# +r0 out. rem: 0.36216201\n",
    "# + models 10-20: 0.45574288\n",
    "# + models 1,2,6,7,8,9,10,5,3,4: 0.42359094\n",
    "# + models 1,2,6-15,5,3,4: 0.44986680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.04441391\n",
      "Score for event 1000: 0.06550528\n",
      "Score for event 1000: 0.06957069\n",
      "Score for event 1000: 0.07678826\n",
      "Score for event 1000: 0.07941898\n",
      "Score for event 1000: 0.09149716\n",
      "Score for event 1000: 0.09832986\n",
      "Score for event 1000: 0.10038455\n",
      "Score for event 1000: 0.10169605\n",
      "Score for event 1000: 0.10249580\n"
     ]
    }
   ],
   "source": [
    "w2_lbl = weak_labels[0:8]\n",
    "w2_lbl.append(weak_labels[-3])\n",
    "w2_lbl.append(weak_labels[-2])\n",
    "w2_lbl.append(weak_labels[-1])\n",
    "weak_merged = merge_all_labels(w2_lbl, hits, truth)\n",
    "#weak_merged = merge_all_labels(weak_labels, hits, truth)\n",
    "# 0.5 cutoff: 0.09220529\n",
    "# 0.5 cutoff + outlier rem: 0.08541034\n",
    "# + r0 out. rem: 0.08497520\n",
    "# + models 10-20: 0.11515280\n",
    "# + models 1,2,6,7,8,9,10,5,3,4: 0.10249580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.73329531\n"
     ]
    }
   ],
   "source": [
    "labels_merged = merge.heuristic_merge_tracks(strong_merged, medium_merged, hits, overwrite_limit=3, print_summary=False)\n",
    "score_one_submission(event_id, hits, labels_merged, truth)\n",
    "# strong=0.1 cutoff: 0.7186 (overwrite=3)\n",
    "# strong=0.15 cutoff: 0.7192 (overwrite=3)\n",
    "# strong=0.2 cutoff: 0.7196\n",
    "# outlier rem., 0.2 cutoff: 0.7246\n",
    "# + r0 out. rem: 0.7260\n",
    "# + models 10-20: 0.73364939\n",
    "# only 10 medium models: 0.73336881\n",
    "# only 15 medium models: 0.73329531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.73671680\n"
     ]
    }
   ],
   "source": [
    "labels_merged2 = merge.heuristic_merge_tracks(labels_merged, weak_merged, hits, overwrite_limit=1, print_summary=False)\n",
    "score_one_submission(event_id, hits, labels_merged2, truth)\n",
    "# strong=0.1 cutoff: 0.7228 (overwrite=1)\n",
    "# strong=0.15 cutoff: 0.7237 (overwrite=1)\n",
    "# strong=0.2 cutoff: 0.7241 (overwrite=1)\n",
    "# outlier rem. strong=0.2: 0.7293\n",
    "# +r0 out. rem: 0.7311\n",
    "# +models 10-14: 0.735?\n",
    "# + models 10-20: 0.73648855\n",
    "# only 10 weak models: 0.73707780\n",
    "# only 15 medium models: 0.73671680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.73724001\n",
      "Score for event 1000: 0.73845154\n"
     ]
    }
   ],
   "source": [
    "labels = strt.extend_straight_tracks(labels_merged2, hits)\n",
    "score_one_submission(event_id, hits, labels, truth)\n",
    "labels = free.assign_free_hits(labels, hits)\n",
    "score_one_submission(event_id, hits, labels, truth)\n",
    "# scores: 0.73736782, 0.73874326\n",
    "# only 15 medium models: 0.73845154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_helix6f = remove_outliers2(labels_helix6, hits, cells, print_counts=True)\n",
    "score_one_submission(event_id, hits, labels_helix6, truth)\n",
    "score_one_submission(event_id, hits, labels_helix6f, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_track_outliers2(track, labels, hits, cells, aggressive):\n",
    "    labels = np.copy(labels)\n",
    "    found_bad_volume = 0\n",
    "    found_bad_cell = 0\n",
    "    found_bad_dimension = 0\n",
    "    found_bad_slope = 0\n",
    "    found_bad_z = 0\n",
    "    found_bad_zr = 0\n",
    "\n",
    "    if True:\n",
    "        outlier_zr = zro.find_track_outliers_zr(track, labels, hits)\n",
    "        if len(outlier_zr) > 0:\n",
    "            #print('track ' + str(track) + ' zr outliers: ' + str(outlier_zr))\n",
    "            found_bad_zr = found_bad_zr + len(outlier_zr)\n",
    "            for oix in outlier_zr:\n",
    "                labels[oix] = 0\n",
    "\n",
    "    if True:\n",
    "        # Check if the sorted hits (on z-axis) go through the volumes\n",
    "        # and layers in the expected order\n",
    "        duplicatez_ix = merge.find_duplicate_z_using_zr(track, labels, hits)\n",
    "        if len(duplicatez_ix) > 0:\n",
    "            #print('track ' + str(track) + ' duplicate z: ' + str(duplicatez_ix))\n",
    "            found_bad_z = found_bad_z + len(duplicatez_ix)\n",
    "            for bzix in duplicatez_ix:\n",
    "                labels[bzix] = 0\n",
    "\n",
    "    if False:#True:\n",
    "        # Check the helix slope, discard hits that do not match\n",
    "        outlier_slope_ix = merge.remove_track_outliers_slope(track, labels, hits)\n",
    "        if len(outlier_slope_ix) > 0:\n",
    "            #print('track ' + str(track) + ' slope outliers: ' + str(outlier_slope_ix))\n",
    "            found_bad_slope = found_bad_slope + len(outlier_slope_ix)\n",
    "            for oix in outlier_slope_ix:\n",
    "                labels[oix] = 0\n",
    "\n",
    "    return (labels, found_bad_volume, found_bad_dimension, found_bad_z, found_bad_slope, found_bad_zr, found_bad_cell)\n",
    "\n",
    "\n",
    "def remove_outliers2(labels, hits, cells, smallest_track_size=2, aggressive=False, print_counts=True):\n",
    "    tracks = np.unique(labels)\n",
    "    hits['z_abs'] = hits.z.abs()\n",
    "    hits['r'] = np.sqrt(hits.x**2+hits.y**2)\n",
    "    hits['a0'] = np.arctan2(hits.y,hits.x)\n",
    "    hits['zr'] = hits['z'] / hits['r']\n",
    "    count_rem_volume = 0\n",
    "    count_rem_dimension = 0\n",
    "    count_duplicatez = 0\n",
    "    count_rem_slope = 0\n",
    "    count_small_tracks = 0\n",
    "    count_zr = 0\n",
    "    count_cell = 0\n",
    "    for track in tracks:\n",
    "        if track == 0:\n",
    "            continue\n",
    "        track_hits = np.where(labels == track)[0]\n",
    "        if len(track_hits) > 3:\n",
    "            (labels, c1, c2, c3, c4, c5, c6) = remove_track_outliers2(track, labels, hits, cells, aggressive)\n",
    "            count_rem_volume = count_rem_volume + c1\n",
    "            count_rem_dimension = count_rem_dimension + c2\n",
    "            count_duplicatez = count_duplicatez + c3\n",
    "            count_rem_slope = count_rem_slope + c4\n",
    "            count_zr = count_zr + c5\n",
    "            count_cell = count_cell + c6\n",
    "\n",
    "    # Remove small tracks, we do not get any score for those. This is done\n",
    "    # last, in case removing the outliers (above) removed enough hits\n",
    "    # from a track to make them smaller than the threshold.\n",
    "    (labels, count_small_tracks) = merge.remove_small_tracks(labels, smallest_track_size=smallest_track_size)\n",
    "\n",
    "    if print_counts:\n",
    "        print('Total removed due to bad cells: ' + str(count_cell))\n",
    "        print('Total removed due to bad volumes: ' + str(count_rem_volume))\n",
    "        print('Total removed due to bad zr values: ' + str(count_zr))\n",
    "        print('Total removed due to bad dimensions: ' + str(count_rem_dimension))\n",
    "        print('Total removed due to duplicate zs: ' + str(count_duplicatez))\n",
    "        print('Total removed due to bad slopes: ' + str(count_rem_slope))\n",
    "        print('Total removed small tracks (<' + str(smallest_track_size) + ') hits: ' + str(count_small_tracks))\n",
    "\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

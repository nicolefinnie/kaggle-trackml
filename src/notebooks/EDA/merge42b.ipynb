{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import collections as coll\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import merge as merge\n",
    "import extension as ext\n",
    "import zroutlier as zro\n",
    "import free_hits as free\n",
    "import track_score as score2\n",
    "import straight_tracks as strt\n",
    "import eda_utils as eda\n",
    "import r0outlier as r0o\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../../../input/train_1'\n",
    "event_id = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event000001000 memory usage 18.46 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "event_prefix = 'event00000' + str(event_id)\n",
    "hits, cells, particles, truth = load_event(os.path.join(TRAIN_PATH, event_prefix))\n",
    "\n",
    "mem_bytes = (hits.memory_usage(index=True).sum() \n",
    "             + cells.memory_usage(index=True).sum() \n",
    "             + particles.memory_usage(index=True).sum() \n",
    "             + truth.memory_usage(index=True).sum())\n",
    "print('{} memory usage {:.2f} MB'.format(event_prefix, mem_bytes / 2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "helix_root_path = '../../1000_r0_exp3/event_' + str(event_id) + '_labels_train_helix'\n",
    "labels_helix1 = pd.read_csv(helix_root_path + '1.csv').label.values\n",
    "labels_helix2 = pd.read_csv(helix_root_path + '2.csv').label.values\n",
    "labels_helix3 = pd.read_csv(helix_root_path + '3.csv').label.values\n",
    "labels_helix4 = pd.read_csv(helix_root_path + '4.csv').label.values\n",
    "labels_helix5 = pd.read_csv(helix_root_path + '5.csv').label.values\n",
    "labels_helix6 = pd.read_csv(helix_root_path + '6.csv').label.values\n",
    "labels_helix7 = pd.read_csv(helix_root_path + '7.csv').label.values\n",
    "labels_helix8 = pd.read_csv(helix_root_path + '8.csv').label.values\n",
    "labels_helix9 = pd.read_csv(helix_root_path + '9.csv').label.values\n",
    "labels_helix10 = pd.read_csv(helix_root_path + '10.csv').label.values\n",
    "labels_helix11 = pd.read_csv(helix_root_path + '11.csv').label.values\n",
    "labels_helix12 = pd.read_csv(helix_root_path + '12.csv').label.values\n",
    "labels_helix13 = pd.read_csv(helix_root_path + '13.csv').label.values\n",
    "labels_helix14 = pd.read_csv(helix_root_path + '14.csv').label.values\n",
    "labels_helix15 = pd.read_csv(helix_root_path + '15.csv').label.values\n",
    "labels_helix16 = pd.read_csv(helix_root_path + '16.csv').label.values\n",
    "labels_helix17 = pd.read_csv(helix_root_path + '17.csv').label.values\n",
    "labels_helix18 = pd.read_csv(helix_root_path + '18.csv').label.values\n",
    "labels_helix19 = pd.read_csv(helix_root_path + '19.csv').label.values\n",
    "labels_helix20 = pd.read_csv(helix_root_path + '20.csv').label.values\n",
    "labels_helix21 = pd.read_csv(helix_root_path + '21.csv').label.values\n",
    "labels_helix22 = pd.read_csv(helix_root_path + '22.csv').label.values\n",
    "labels_helix23 = pd.read_csv(helix_root_path + '23.csv').label.values\n",
    "labels_helix24 = pd.read_csv(helix_root_path + '24.csv').label.values\n",
    "labels_helix25 = pd.read_csv(helix_root_path + '25.csv').label.values\n",
    "labels_helix26 = pd.read_csv(helix_root_path + '26.csv').label.values\n",
    "labels_helix27 = pd.read_csv(helix_root_path + '27.csv').label.values\n",
    "labels_helix28 = pd.read_csv(helix_root_path + '28.csv').label.values\n",
    "labels_helix29 = pd.read_csv(helix_root_path + '29.csv').label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission\n",
    "\n",
    "def score_one_submission(event_id, hits, labels, truth):\n",
    "    submission = create_one_event_submission(event_id, hits, labels)\n",
    "    score = score_event(truth, submission)\n",
    "    print(\"Score for event %d: %.8f\" % (event_id, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block if you want to see the distribution of perfect vs short vs imperfect vs horrible\n",
    "# tracks, by comparing to ground truth\n",
    "helix6 = np.copy(labels_helix9)\n",
    "#helix6 = merge.remove_outliers(helix6, hits, smallest_track_size=6, aggressive=False, print_counts=False)\n",
    "(helix6, small_count) = merge.remove_small_tracks(helix6, smallest_track_size=6)\n",
    "#helix6 = r0o.remove_badr0_tracks(helix6, hits)\n",
    "helix6 = merge.renumber_labels(helix6)\n",
    "tracks = np.unique(helix6)\n",
    "short_tracks = []\n",
    "perfect_tracks = []\n",
    "imperfect_tracks = []\n",
    "horrible_tracks = []\n",
    "for track in tracks:\n",
    "    if track == 0: continue\n",
    "    tix = np.where(helix6 == track)[0]\n",
    "    if len(tix) < 6: continue\n",
    "    else:\n",
    "        (is_match, correct,incorrect) = eda.track_distance_from_truth(track, helix6, hits, truth)\n",
    "        if is_match:\n",
    "            perfect_tracks.append(track)\n",
    "        elif incorrect == 0:\n",
    "            short_tracks.append(track)\n",
    "        elif incorrect <= 4 and correct >= incorrect:\n",
    "            imperfect_tracks.append(track)\n",
    "        else:\n",
    "            horrible_tracks.append(track)\n",
    "\n",
    "print('Total tracks:     ' + str(len(tracks)))\n",
    "print('Perfect tracks:   ' + str(len(perfect_tracks)))\n",
    "print('Short tracks:     ' + str(len(short_tracks)))\n",
    "print('Imperfect tracks: ' + str(len(imperfect_tracks)))\n",
    "print('Horrible tracks:  ' + str(len(horrible_tracks)))\n",
    "# Helix1: 8143, perfect 1972, short 1364, imperfect 3547, horrible 1259\n",
    "# Helix2: 7666, perfect 2020, short 1170, imperfect 3522, horrible 953\n",
    "# Helix3: 6717, perfect 1783, short 1589, imperfect 2696, horrible 648\n",
    "# Helix4: 6688, perfect 1547, short 1649, imperfect 2780, horrible 711\n",
    "# Helix5: 6645, perfect 1600, short 1763, imperfect 2781, horrible 500\n",
    "# Helix6: 7436, perfect 1755, short 1716, imperfect 3361, horrible 603\n",
    "# Helix7: 7451, perfect 1795, short 1795, imperfect 3299, horrible 589\n",
    "# Helix8: 7421, perfect 1734, short 1638, imperfect 3302, horrible 746\n",
    "# Helix9: 7414, perfect 1807, short 1699, imperfect 3276, horrible 631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_track_quality(labels, hits, truth):\n",
    "    tracks, counts = np.unique(labels, return_counts=True)\n",
    "    short_tracks = 0\n",
    "    perfect_tracks = 0\n",
    "    imperfect_tracks = 0\n",
    "    horrible_tracks = 0\n",
    "    for ix, track in enumerate(tracks):\n",
    "        if track == 0: continue\n",
    "        if counts[ix] < 6: continue\n",
    "\n",
    "        (is_match, correct,incorrect) = eda.track_distance_from_truth(track, labels, hits, truth)\n",
    "        if is_match:\n",
    "            perfect_tracks = perfect_tracks + 1\n",
    "        elif incorrect == 0:\n",
    "            short_tracks = short_tracks + 1\n",
    "        elif incorrect <= 4 and correct >= incorrect:\n",
    "            imperfect_tracks = imperfect_tracks + 1\n",
    "        else:\n",
    "            horrible_tracks = horrible_tracks + 1\n",
    "\n",
    "    print('Total tracks:     ' + str(len(tracks)))\n",
    "    print('Perfect tracks:   ' + str(perfect_tracks))\n",
    "    print('Short tracks:     ' + str(short_tracks))\n",
    "    print('Imperfect tracks: ' + str(imperfect_tracks))\n",
    "    print('Horrible tracks:  ' + str(horrible_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.copy(labels_helix6)\n",
    "score_one_submission(event_id, hits, labels, truth) # 0.63580502\n",
    "(strong, medium, weak) = r0o.split_tracks_based_on_quality(labels, hits)\n",
    "score_one_submission(event_id, hits, strong, truth)\n",
    "score_one_submission(event_id, hits, medium, truth)\n",
    "score_one_submission(event_id, hits, weak, truth)\n",
    "# (0.5 weak, 0.1 strong): 0.28793004 (1776/3737), 0.31400817 (1582/5075), 0.03201160 (28/646)\n",
    "# (0.5 weak, 0.15 strong): 0.35599925 (2247/4484), 0.24593896 (1111/4328), 0.03201160 (28/646)\n",
    "# (0.5 weak, 0.2 strong): 0.40582813 (2604/5035), 0.19611008 (754/3777), 0.03201160 (28/646)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_track_quality(strong, hits, truth)\n",
    "display_track_quality(medium, hits, truth)\n",
    "display_track_quality(weak, hits, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_helix1 = merge.remove_outliers(labels_helix1, hits, cells, aggressive=True, print_counts=False)\n",
    "labels_helix2 = merge.remove_outliers(labels_helix2, hits, cells, aggressive=True, print_counts=False)\n",
    "labels_helix3 = merge.remove_outliers(labels_helix3, hits, cells, aggressive=True, print_counts=False)\n",
    "labels_helix4 = merge.remove_outliers(labels_helix4, hits, cells, aggressive=True, print_counts=False)\n",
    "labels_helix5 = merge.remove_outliers(labels_helix5, hits, cells, aggressive=True, print_counts=False)\n",
    "# LIAM: Add more outlier removal here. Explore different cutoffs (> 0.2?)\n",
    "labels_helix1 = r0o.remove_badr0_tracks(labels_helix1, hits)\n",
    "labels_helix2 = r0o.remove_badr0_tracks(labels_helix2, hits)\n",
    "labels_helix3 = r0o.remove_badr0_tracks(labels_helix3, hits)\n",
    "labels_helix4 = r0o.remove_badr0_tracks(labels_helix4, hits)\n",
    "labels_helix5 = r0o.remove_badr0_tracks(labels_helix5, hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_labels.append(labels_helix1)\n",
    "all_labels.append(labels_helix2)\n",
    "all_labels.append(labels_helix6)\n",
    "all_labels.append(labels_helix7)\n",
    "all_labels.append(labels_helix8)\n",
    "all_labels.append(labels_helix9)\n",
    "all_labels.append(labels_helix10)\n",
    "all_labels.append(labels_helix11)\n",
    "all_labels.append(labels_helix12)\n",
    "all_labels.append(labels_helix13)\n",
    "all_labels.append(labels_helix14)\n",
    "all_labels.append(labels_helix15)\n",
    "all_labels.append(labels_helix16)\n",
    "#all_labels.append(labels_helix17)\n",
    "#all_labels.append(labels_helix18)\n",
    "#all_labels.append(labels_helix19)\n",
    "all_labels.append(labels_helix20)\n",
    "#all_labels.append(labels_helix21)\n",
    "#all_labels.append(labels_helix22)\n",
    "#all_labels.append(labels_helix23)\n",
    "#all_labels.append(labels_helix24)\n",
    "#all_labels.append(labels_helix25)\n",
    "#all_labels.append(labels_helix26)\n",
    "#all_labels.append(labels_helix27)\n",
    "#all_labels.append(labels_helix28)\n",
    "#all_labels.append(labels_helix29)\n",
    "all_labels.append(labels_helix5)\n",
    "all_labels.append(labels_helix3)\n",
    "all_labels.append(labels_helix4)\n",
    "strong_labels = []\n",
    "medium_labels = []\n",
    "weak_labels = []\n",
    "for label in all_labels:\n",
    "    (strong, medium, weak) = r0o.split_tracks_based_on_quality(label, hits)\n",
    "    strong_labels.append(strong)\n",
    "    medium_labels.append(medium)\n",
    "    weak_labels.append(weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_labels(all_labels, hits, truth):\n",
    "    merge_count = 0\n",
    "    labels_merged = np.copy(all_labels[0])\n",
    "    for i in range(len(all_labels)):\n",
    "        if i == 0: continue\n",
    "        labels_merged = merge.heuristic_merge_tracks(labels_merged, all_labels[i], hits, overwrite_limit=6, print_summary=False)\n",
    "        merge_count = merge_count + 1\n",
    "        #message = 'Merged loop 1-' + str(i+1) + ' score for event '\n",
    "        #display_score(event_id, hits, labels_merged, truth, message)\n",
    "        score_one_submission(event_id, hits, labels_merged, truth)\n",
    "    return labels_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = merge_all_labels(all_labels, hits, truth)\n",
    "# No outlier removal, order 1-9: 0.70948133\n",
    "# outlier removal, 1-2,6-9,5,3,4: 0.71563907\n",
    "# + r0 outlier rem: 0.71652579\n",
    "# + more models(10-20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.51293564\n",
      "Score for event 1000: 0.55977605\n",
      "Score for event 1000: 0.57273489\n",
      "Score for event 1000: 0.58420738\n",
      "Score for event 1000: 0.58764724\n",
      "Score for event 1000: 0.59721682\n",
      "Score for event 1000: 0.60144344\n",
      "Score for event 1000: 0.60531215\n",
      "Score for event 1000: 0.60768387\n",
      "Score for event 1000: 0.61053109\n",
      "Score for event 1000: 0.61255038\n",
      "Score for event 1000: 0.61346986\n",
      "Score for event 1000: 0.61495491\n",
      "Score for event 1000: 0.61579718\n",
      "Score for event 1000: 0.62326064\n",
      "Score for event 1000: 0.62668148\n",
      "Score for event 1000: 0.62794278\n"
     ]
    }
   ],
   "source": [
    "#for ix in range(len(strong_labels)):\n",
    "#    strong_labels[ix] = merge.remove_outliers(strong_labels[ix], hits, cells, aggressive=False, print_counts=False)\n",
    "#strong_labels[0] = merge.remove_outliers(strong_labels[0], hits, cells, aggressive=True, print_counts=False)\n",
    "#strong_labels[1] = merge.remove_outliers(strong_labels[0], hits, cells, aggressive=True, print_counts=False)\n",
    "#strong_labels[-3] = merge.remove_outliers(strong_labels[-3], hits, cells, aggressive=True, print_counts=False)\n",
    "#strong_labels[-2] = merge.remove_outliers(strong_labels[-2], hits, cells, aggressive=True, print_counts=False)\n",
    "#strong_labels[-1] = merge.remove_outliers(strong_labels[-1], hits, cells, aggressive=True, print_counts=False)\n",
    "\n",
    "strong_merged = merge_all_labels(strong_labels, hits, truth)\n",
    "# 0.1 cutoff: 0.47028638\n",
    "# 0.15 cutoff: 0.54866460\n",
    "# 0.2 cutoff: 0.59883933\n",
    "# outlier rem, 0.2 cutoff: 0.60684391\n",
    "# +r0 out. rem: 0.60669428\n",
    "# + models 10-20: 0.62883099\n",
    "# + non-aggr. removal: 0.62445889\n",
    "# + non-aggr removal helix1-5: 0.61959276\n",
    "# aggr removal helix1-5: 0.62014222\n",
    "# r0 rem 1-5, aggr rem 1-5: 0.62036476\n",
    "# aggr + r0 rem 1-5, non-aggr 1-29: 0.63106388 (WRONG)\n",
    "# aggr + r0 rem 1-5, non-aggr 1-29: 0.63576178\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.62794278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.22760629\n",
      "Score for event 1000: 0.28729900\n",
      "Score for event 1000: 0.31137640\n",
      "Score for event 1000: 0.33276157\n",
      "Score for event 1000: 0.34104471\n",
      "Score for event 1000: 0.38566285\n",
      "Score for event 1000: 0.40904801\n",
      "Score for event 1000: 0.41738492\n",
      "Score for event 1000: 0.42570800\n",
      "Score for event 1000: 0.43047799\n",
      "Score for event 1000: 0.43516841\n",
      "Score for event 1000: 0.43874598\n",
      "Score for event 1000: 0.44033973\n",
      "Score for event 1000: 0.44203304\n",
      "Score for event 1000: 0.44744311\n",
      "Score for event 1000: 0.45036405\n",
      "Score for event 1000: 0.45258828\n"
     ]
    }
   ],
   "source": [
    "#for ix in range(len(medium_labels)):\n",
    "#    medium_labels[ix] = merge.remove_outliers(medium_labels[ix], hits, cells, aggressive=True, print_counts=False)\n",
    "#medium_labels[0] = merge.remove_outliers(medium_labels[0], hits, cells, aggressive=True, print_counts=False)\n",
    "#medium_labels[1] = merge.remove_outliers(medium_labels[0], hits, cells, aggressive=True, print_counts=False)\n",
    "#medium_labels[-3] = merge.remove_outliers(medium_labels[-3], hits, cells, aggressive=True, print_counts=False)\n",
    "#medium_labels[-2] = merge.remove_outliers(medium_labels[-2], hits, cells, aggressive=True, print_counts=False)\n",
    "#medium_labels[-1] = merge.remove_outliers(medium_labels[-1], hits, cells, aggressive=True, print_counts=False)\n",
    "#for ix in range(len(medium_labels)):\n",
    "#    #if ix == 0 or ix == 1 or ix == 17 or ix == 18 or ix == 19:\n",
    "#    #    medium_labels[ix] = merge.remove_outliers(medium_labels[ix], hits, cells, aggressive=True, print_counts=False)\n",
    "#    #    #medium_labels[ix] = r0o.remove_badr0_tracks(medium_labels[ix], hits)\n",
    "#    #else:\n",
    "#    medium_labels[ix] = merge.remove_outliers(medium_labels[ix], hits, cells, aggressive=False, print_counts=False)\n",
    "\n",
    "medium_merged = merge_all_labels(medium_labels, hits, truth)\n",
    "# 0.1 cutoff: 0.50709876\n",
    "# 0.15 cutoff: 0.43838218\n",
    "# 0.2 cutoff: 0.38796599\n",
    "# outlier rem, 0.2 cutoff: 0.36414178\n",
    "# +r0 out. rem: 0.36216201\n",
    "# + models 10-20: 0.45574288\n",
    "# + aggr rem: 0.47067715\n",
    "# + aggr rem helix1-5: 0.45481563\n",
    "# aggr rem + r0 1-5, non-aggr 6-20: 0.46889905\n",
    "# r0 rem + aggr 1-5, non-aggr 6-20: 0.46823429\n",
    "# aggr + r0 rem 1-5, aggr 1-5, non-aggr 6-29: 0.48524563 (WRONG)\n",
    "# aggr + r0 rem 1-5, aggr 1-5, non-aggr 6-29: 0.47261116\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.45258828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.04441391\n",
      "Score for event 1000: 0.06550528\n",
      "Score for event 1000: 0.06957069\n",
      "Score for event 1000: 0.07678826\n",
      "Score for event 1000: 0.07941898\n",
      "Score for event 1000: 0.09149716\n",
      "Score for event 1000: 0.09832986\n",
      "Score for event 1000: 0.10168781\n",
      "Score for event 1000: 0.10326102\n",
      "Score for event 1000: 0.10467413\n",
      "Score for event 1000: 0.10697252\n",
      "Score for event 1000: 0.10743883\n",
      "Score for event 1000: 0.10847402\n",
      "Score for event 1000: 0.10973217\n",
      "Score for event 1000: 0.11164060\n",
      "Score for event 1000: 0.11276428\n",
      "Score for event 1000: 0.11333906\n"
     ]
    }
   ],
   "source": [
    "#for ix in range(len(weak_labels)):\n",
    "#    weak_labels[ix] = merge.remove_outliers(weak_labels[ix], hits, cells, aggressive=False, print_counts=False)\n",
    "#    #weak_labels[ix] = r0o.remove_badr0_tracks(weak_labels[ix], hits)\n",
    "weak_merged = merge_all_labels(weak_labels, hits, truth)\n",
    "# 0.5 cutoff: 0.09220529\n",
    "# 0.5 cutoff + outlier rem: 0.08541034\n",
    "# + r0 out. rem: 0.08497520\n",
    "# + models 10-20: 0.11515280\n",
    "# + aggr rem: 0.12140712\n",
    "# aggr rem + r0 1-20: 0.12149158\n",
    "# r0 + aggr rem + r0: 0.12124078\n",
    "# aggr + r0 rem 1-5, aggr + r0 1-29: 0.13490835 (WRONG)\n",
    "# aggr + r0 rem 1-5, aggr + r0 1-29: 0.12936853\n",
    "# non-aggr 1-29: 0.12986241\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.11333906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.45130461\n",
      "Score for event 1000: 0.73398978\n"
     ]
    }
   ],
   "source": [
    "#labels_merged = merge.heuristic_merge_tracks(strong_merged, medium_merged, hits, overwrite_limit=3, print_summary=False)\n",
    "#score_one_submission(event_id, hits, labels_merged, truth)\n",
    "\n",
    "#sm1 = np.copy(strong_merged)\n",
    "#sm1 = merge.remove_outliers(sm1, hits, cells, aggressive=False, print_counts=False)\n",
    "#score_one_submission(event_id, hits, sm1, truth)\n",
    "\n",
    "mm1 = np.copy(medium_merged)\n",
    "mm1 = merge.remove_outliers(mm1, hits, cells, aggressive=False, print_counts=False)\n",
    "score_one_submission(event_id, hits, mm1, truth)\n",
    "\n",
    "labels_merged = merge.heuristic_merge_tracks(strong_merged, mm1, hits, weak_tracks=True, overwrite_limit=3, print_summary=False)\n",
    "score_one_submission(event_id, hits, labels_merged, truth)\n",
    "\n",
    "\n",
    "# strong=0.1 cutoff: 0.7186 (overwrite=3)\n",
    "# strong=0.15 cutoff: 0.7192 (overwrite=3)\n",
    "# strong=0.2 cutoff: 0.7196\n",
    "# outlier rem., 0.2 cutoff: 0.7246\n",
    "# + r0 out. rem: 0.7260\n",
    "# + models 10-20: 0.73364939\n",
    "# + aggr rem: 0.72843570\n",
    "# mix. aggr: 0.73158799\n",
    "# new outl. rem.: 0.73205202\n",
    "# 1-30 model: 0.73230790 (WRONG)\n",
    "# 1-30 model: 0.73269197\n",
    "# non-aggr: 0.73271879\n",
    "# end outlier removal before merge: 0.73368874\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.73398978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_one_submission(event_id, hits, labels, truth)\n",
    "qqq = np.copy(labels)\n",
    "qqq = extend_straight_tracks2(qqq, hits, sandwich_only=True)\n",
    "score_one_submission(event_id, hits, qqq, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.11188693\n",
      "Score for event 1000: 0.73868537\n"
     ]
    }
   ],
   "source": [
    "wm1 = np.copy(weak_merged)\n",
    "wm1 = merge.remove_outliers(wm1, hits, cells, aggressive=True, print_counts=False)\n",
    "score_one_submission(event_id, hits, wm1, truth)\n",
    "\n",
    "labels_merged2 = merge.heuristic_merge_tracks(labels_merged, wm1, hits, weak_tracks=True, overwrite_limit=1, print_summary=False)\n",
    "score_one_submission(event_id, hits, labels_merged2, truth)\n",
    "# strong=0.1 cutoff: 0.7228 (overwrite=1)\n",
    "# strong=0.15 cutoff: 0.7237 (overwrite=1)\n",
    "# strong=0.2 cutoff: 0.7241 (overwrite=1)\n",
    "# outlier rem. strong=0.2: 0.7293\n",
    "# +r0 out. rem: 0.7311\n",
    "# +models 10-14: 0.735?\n",
    "# + aggr rem: 0.73156373\n",
    "# mix aggr: 0.73515061\n",
    "# new outl. rem.: 0.73566226\n",
    "# 1-30 model: 0.73579791 (WRONG)\n",
    "# 1-30 model: 0.73518289\n",
    "# non-aggr: 0.73500790\n",
    "# end outlier removal before merge: 0.73610233\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.73868537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.73919425\n",
      "Score for event 1000: 0.74052860\n"
     ]
    }
   ],
   "source": [
    "labels = strt.extend_straight_tracks(labels_merged2, hits)\n",
    "score_one_submission(event_id, hits, labels, truth)\n",
    "labels = free.assign_free_hits(labels, hits)\n",
    "score_one_submission(event_id, hits, labels, truth)\n",
    "# scores: 0.73572726, 0.73764864\n",
    "# scores: 0.73207606, 0.73352547\n",
    "# mix aggr: 0.73568387, 0.73702418\n",
    "# new outl. rem.: 0.73622403, 0.73765638\n",
    "# 1-30 model: 0.73631656, 0.73772902 (WRONG)\n",
    "# 1-30 model: 0.73562457, 0.73714515\n",
    "# non-aggr: 0.73543950, 0.73702604\n",
    "# end outlier removal before merge: 0.73656246, 0.73780084\n",
    "# aggr + r0 rem 1-5, no model 17,19: 0.73919425, 0.74052860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_helix6f = remove_outliers2(labels_helix6, hits, cells, print_counts=True)\n",
    "score_one_submission(event_id, hits, labels_helix6, truth)\n",
    "score_one_submission(event_id, hits, labels_helix6f, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_track_outliers2(track, labels, hits, cells, aggressive):\n",
    "    labels = np.copy(labels)\n",
    "    found_bad_volume = 0\n",
    "    found_bad_cell = 0\n",
    "    found_bad_dimension = 0\n",
    "    found_bad_slope = 0\n",
    "    found_bad_z = 0\n",
    "    found_bad_zr = 0\n",
    "\n",
    "    if True:\n",
    "        outlier_zr = zro.find_track_outliers_zr(track, labels, hits)\n",
    "        if len(outlier_zr) > 0:\n",
    "            #print('track ' + str(track) + ' zr outliers: ' + str(outlier_zr))\n",
    "            found_bad_zr = found_bad_zr + len(outlier_zr)\n",
    "            for oix in outlier_zr:\n",
    "                labels[oix] = 0\n",
    "\n",
    "    if True:\n",
    "        # Check if the sorted hits (on z-axis) go through the volumes\n",
    "        # and layers in the expected order\n",
    "        duplicatez_ix = merge.find_duplicate_z_using_zr(track, labels, hits)\n",
    "        if len(duplicatez_ix) > 0:\n",
    "            #print('track ' + str(track) + ' duplicate z: ' + str(duplicatez_ix))\n",
    "            found_bad_z = found_bad_z + len(duplicatez_ix)\n",
    "            for bzix in duplicatez_ix:\n",
    "                labels[bzix] = 0\n",
    "\n",
    "    if False:#True:\n",
    "        # Check the helix slope, discard hits that do not match\n",
    "        outlier_slope_ix = merge.remove_track_outliers_slope(track, labels, hits)\n",
    "        if len(outlier_slope_ix) > 0:\n",
    "            #print('track ' + str(track) + ' slope outliers: ' + str(outlier_slope_ix))\n",
    "            found_bad_slope = found_bad_slope + len(outlier_slope_ix)\n",
    "            for oix in outlier_slope_ix:\n",
    "                labels[oix] = 0\n",
    "\n",
    "    return (labels, found_bad_volume, found_bad_dimension, found_bad_z, found_bad_slope, found_bad_zr, found_bad_cell)\n",
    "\n",
    "\n",
    "def remove_outliers2(labels, hits, cells, smallest_track_size=2, aggressive=False, print_counts=True):\n",
    "    tracks = np.unique(labels)\n",
    "    hits['z_abs'] = hits.z.abs()\n",
    "    hits['r'] = np.sqrt(hits.x**2+hits.y**2)\n",
    "    hits['a0'] = np.arctan2(hits.y,hits.x)\n",
    "    hits['zr'] = hits['z'] / hits['r']\n",
    "    count_rem_volume = 0\n",
    "    count_rem_dimension = 0\n",
    "    count_duplicatez = 0\n",
    "    count_rem_slope = 0\n",
    "    count_small_tracks = 0\n",
    "    count_zr = 0\n",
    "    count_cell = 0\n",
    "    for track in tracks:\n",
    "        if track == 0:\n",
    "            continue\n",
    "        track_hits = np.where(labels == track)[0]\n",
    "        if len(track_hits) > 3:\n",
    "            (labels, c1, c2, c3, c4, c5, c6) = remove_track_outliers2(track, labels, hits, cells, aggressive)\n",
    "            count_rem_volume = count_rem_volume + c1\n",
    "            count_rem_dimension = count_rem_dimension + c2\n",
    "            count_duplicatez = count_duplicatez + c3\n",
    "            count_rem_slope = count_rem_slope + c4\n",
    "            count_zr = count_zr + c5\n",
    "            count_cell = count_cell + c6\n",
    "\n",
    "    # Remove small tracks, we do not get any score for those. This is done\n",
    "    # last, in case removing the outliers (above) removed enough hits\n",
    "    # from a track to make them smaller than the threshold.\n",
    "    (labels, count_small_tracks) = merge.remove_small_tracks(labels, smallest_track_size=smallest_track_size)\n",
    "\n",
    "    if print_counts:\n",
    "        print('Total removed due to bad cells: ' + str(count_cell))\n",
    "        print('Total removed due to bad volumes: ' + str(count_rem_volume))\n",
    "        print('Total removed due to bad zr values: ' + str(count_zr))\n",
    "        print('Total removed due to bad dimensions: ' + str(count_rem_dimension))\n",
    "        print('Total removed due to duplicate zs: ' + str(count_duplicatez))\n",
    "        print('Total removed due to bad slopes: ' + str(count_rem_slope))\n",
    "        print('Total removed small tracks (<' + str(smallest_track_size) + ') hits: ' + str(count_small_tracks))\n",
    "\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
